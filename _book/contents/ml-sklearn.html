
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <title>Scikit-Learn · HonKit</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 3.7.1">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="intro-tensorflow.html" />
    
    
    <link rel="prev" href="ml-101.html" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Entendendo Machine Learning com Scikit-Learn e TensorFlow na prática
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.1" data-path="sobre-o-livro.html">
            
                <a href="sobre-o-livro.html">
            
                    
                    Para quem é este livro?
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.2" data-path="ambiente.html">
            
                <a href="ambiente.html">
            
                    
                    Configurando o ambiente
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.3" data-path="../xx">
            
                <span>
            
                    
                    Um pouco de Python para Data Science
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="part-i-data-science.html">
            
                <a href="part-i-data-science.html">
            
                    
                    Parte I: Data Science
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="conhecendo-o-pandas.html">
            
                <a href="conhecendo-o-pandas.html">
            
                    
                    Conhecendo o Pandas
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.1" data-path="conhecendo-o-pandas.html">
            
                <a href="conhecendo-o-pandas.html#importando-o-pandas">
            
                    
                    Importando o Pandas
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.2" data-path="series-dataframe.html">
            
                <a href="series-dataframe.html">
            
                    
                    Series e DataFrames
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3" data-path="series-dataframe.html">
            
                <a href="series-dataframe.html#series">
            
                    
                    Series
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.4" data-path="series-dataframe.html">
            
                <a href="series-dataframe.html#dataframe">
            
                    
                    DataFrame
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.5" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html">
            
                    
                    Manipulando dados
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.6" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#anatomia-de-um-dataframe">
            
                    
                    Anatomia de um DataFrame
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.7" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#explorando-os-dados">
            
                    
                    Explorando os dados
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.8" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#dtypes">
            
                    
                    dtypes
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.9" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#describe">
            
                    
                    describe
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.10" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#info">
            
                    
                    info
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.11" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#mean-e-sum">
            
                    
                    mean, sum
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.12" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#columns">
            
                    
                    columns
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.13" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#head">
            
                    
                    head
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.14" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#tail">
            
                    
                    tail
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.15" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#loc-e-iloc">
            
                    
                    loc, iloc
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.16" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#groupby">
            
                    
                    groupby
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.17" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#replace">
            
                    
                    str.replace
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.18" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#numeric">
            
                    
                    to_numeric
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.19" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#fillna">
            
                    
                    fillna
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.20" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#dropna">
            
                    
                    dropna
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.21" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#drop">
            
                    
                    drop
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.22" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#sample">
            
                    
                    sample
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.23" data-path="manipulando-dados.html">
            
                <a href="manipulando-dados.html#reset-index">
            
                    
                    reset_index
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.24" data-path="pandas-exercicios.html">
            
                <a href="pandas-exercicios.html">
            
                    
                    Exercícios
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="intro-numpy.html">
            
                <a href="intro-numpy.html">
            
                    
                    Introdução ao NumPy
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.2.1" data-path="intro-numpy.html">
            
                <a href="intro-numpy.html#importando-a-biblioteca-numpy">
            
                    
                    Importando a biblioteca NumPy
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.2" data-path="np-tipos-de-dados.html">
            
                <a href="np-tipos-de-dados.html">
            
                    
                    Tipos de dados e atributos
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.3" data-path="np-matrizes-e-operacoes.html">
            
                <a href="np-matrizes-e-operacoes.html">
            
                    
                    Arrays, matrizes e operações
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.4" data-path="np-matrizes-e-operacoes.html">
            
                <a href="np-matrizes-e-operacoes.html#selecionando-e-visualizando-elementos">
            
                    
                    Selecionando e visualizando elementos
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.5" data-path="np-matrizes-e-operacoes.html">
            
                <a href="np-matrizes-e-operacoes.html#manipulando-e-comparando-arrays">
            
                    
                    Manipulando e comparando arrays
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.6" data-path="np-matrizes-e-operacoes.html">
            
                <a href="np-matrizes-e-operacoes.html#aggregations">
            
                    
                    Aggregations
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.7" data-path="np-matrizes-e-operacoes.html">
            
                <a href="np-matrizes-e-operacoes.html#reshaping-e-transpose">
            
                    
                    Reshaping e Transpose
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.8" data-path="np-matrizes-e-operacoes.html">
            
                <a href="np-matrizes-e-operacoes.html#comparando-e-ordenando-arrays">
            
                    
                    Comparando e ordenando arrays
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.9" data-path="numpy-exercicios.html">
            
                <a href="numpy-exercicios.html">
            
                    
                    Exercícios
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="intro-matplotlib.html">
            
                <a href="intro-matplotlib.html">
            
                    
                    Gráficos com Matplotlib
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.3.1" data-path="intro-matplotlib.html">
            
                <a href="intro-matplotlib.html#plot">
            
                    
                    plot
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.2" data-path="intro-matplotlib.html">
            
                <a href="intro-matplotlib.html#figure">
            
                    
                    plt.figure
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.3" data-path="intro-matplotlib.html">
            
                <a href="intro-matplotlib.html#subplots">
            
                    
                    plt.subplots
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.4" data-path="anatomia-matplotlib.html">
            
                <a href="anatomia-matplotlib.html">
            
                    
                    Anatomia de um gráfico
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.5" data-path="matplotlib-plots.html">
            
                <a href="matplotlib-plots.html">
            
                    
                    Tipos de plots mais utilizados
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.6" data-path="matplotlib-plots.html">
            
                <a href="matplotlib-plots.html#line">
            
                    
                    Line
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.7" data-path="matplotlib-plots.html">
            
                <a href="matplotlib-plots.html#scatter">
            
                    
                    Scatter
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.8" data-path="matplotlib-plots.html">
            
                <a href="matplotlib-plots.html#bar">
            
                    
                    Bar
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.9" data-path="matplotlib-plots.html">
            
                <a href="matplotlib-plots.html#hist">
            
                    
                    Hist
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.10" data-path="matplotlib-plots.html">
            
                <a href="matplotlib-plots.html#subplots">
            
                    
                    Subplots
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.11" data-path="matplotlib-plots.html">
            
                <a href="matplotlib-plots.html#plotando-dados-com-pandas">
            
                    
                    Plotando dados com Pandas
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.12" data-path="matplotlib-plots.html">
            
                <a href="matplotlib-plots.html#pandas-plot-line">
            
                    
                    Pandas plot line
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.13" data-path="matplotlib-plots.html">
            
                <a href="matplotlib-plots.html#pandas-plot-scatter">
            
                    
                    Pandas plot scatter
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.14" data-path="matplotlib-plots.html">
            
                <a href="matplotlib-plots.html#pandas-plot-bar">
            
                    
                    Pandas plot bar
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.15" data-path="matplotlib-plots.html">
            
                <a href="matplotlib-plots.html#pandas-plot-hist">
            
                    
                    Pandas plot hist
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.16" data-path="matplotlib-plots.html">
            
                <a href="matplotlib-plots.html#customizando-os-seus-plots">
            
                    
                    Customizando os seus plots
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.17" data-path="matplotlib-plots.html">
            
                <a href="matplotlib-plots.html#adicionando-outro-plot-ao-existente">
            
                    
                    Adicionando outro plot ao existente
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.18" data-path="matplotlib-exercicios.html">
            
                <a href="matplotlib-exercicios.html">
            
                    
                    Exercícios
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="part-ii-ml.html">
            
                <a href="part-ii-ml.html">
            
                    
                    Parte II: Machine Learning
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="ml-101.html">
            
                <a href="ml-101.html">
            
                    
                    O que é Machine Learning?
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.2" data-path="ml-sklearn.html">
            
                <a href="ml-sklearn.html">
            
                    
                    Scikit-Learn
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.2.1" data-path="ml-sklearn.html">
            
                <a href="ml-sklearn.html#sklearn-de-ponta-a-ponta">
            
                    
                    Sklearn de ponta a ponta
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.2" data-path="ml-sklearn.html">
            
                <a href="ml-sklearn.html#eda">
            
                    
                    EDA
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.3" data-path="ml-sklearn.html">
            
                <a href="ml-sklearn.html#modelagem-dos-dados">
            
                    
                    Modelagem dos dados
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.4" data-path="ml-sklearn.html">
            
                <a href="ml-sklearn.html#treino-e-teste">
            
                    
                    Treino e Teste
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.5" data-path="ml-sklearn.html">
            
                <a href="ml-sklearn.html#escolha-de-modelos">
            
                    
                    Escolha de modelos
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.6" data-path="ml-sklearn.html">
            
                <a href="ml-sklearn.html#ajustando-kneighborsclassifier-knn">
            
                    
                    KNeighborsClassifier
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.7" data-path="ml-sklearn.html">
            
                <a href="ml-sklearn.html#ajustando-modelos-com-randomizedsearchcv">
            
                    
                    RandomizedSearchCV
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.8" data-path="ml-sklearn.html">
            
                <a href="ml-sklearn.html#ajustando-modelos-com-gridsearchcv">
            
                    
                    GridSearchCV
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.9" data-path="ml-sklearn.html">
            
                <a href="ml-sklearn.html#roc-curve-e-auc-scores">
            
                    
                    ROC Curve e AUC Scores
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.10" data-path="contents-sklearn.md">
            
                <span>
            
                    
                    Feature importance
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="intro-tensorflow.html">
            
                <a href="intro-tensorflow.html">
            
                    
                    TensorFlow
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.3.1" data-path="intro-tensorflow.html">
            
                <a href="intro-tensorflow.html#tensors">
            
                    
                    Tensors
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.2" data-path="intro-tensorflow.html">
            
                <a href="intro-tensorflow.html#criando-tensors-com-tfconstant">
            
                    
                    Criando Tensors com tf.constant()
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.3" data-path="intro-tensorflow.html">
            
                <a href="intro-tensorflow.html#criando-tensors-com-tfvariable">
            
                    
                    Criando Tensors com tf.Variable()
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Scikit-Learn</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="scikit-learn">Scikit-Learn</h1>
<p>Scikit-Learn, também conhecido como <code>sklearn</code>, é uma biblioteca Python focada em resolver problemas de Machine Learning. Em seu background <code>sklearn</code> utiliza NumPy e Matplotlib.</p>
<p>Embora o campo de Machine Learning seja vasto, o objetivo principal é encontrar padrões nos dados e utilizar esses padrões para tentar fazer previsões. <em>Existem certas categorias nas quais a maioria dos problemas se enquadra</em>.</p>
<p>Digamos que você está tentando desenvolver um modelo de <code>ML</code> para conseguir prever se um email é spam ou não, nesse caso temos um problema de classificação. Agora suponha que você precise criar um modelo para prever o preço de apartamentos de acordo com suas características, agora você tem um problema de regressão (<em>prever um número</em>).</p>
<p>Tudo começa descobrindo primeiro que tipo de problema estamos trabalhando, dependendo do problema, existem etapas semelhantes que devemos seguir para cada caso. Por exemplo, separar os dados em diferentes conjuntos, uma parte para os modelos de Machine Learning aprenderem e outra parte para utilizarmos nos testes. Escolher e avaliar se um modelo de <code>ML</code>  aprendeu alguma coisa.</p>
<p>O Scikit-Learn fornece implementações em Python para realizar todas essas tarefas, evitando a necessidade de ter que construí-los do zero.</p>
<h2 id="sklearn-de-ponta-a-ponta">Sklearn de ponta a ponta</h2>
<p>Veremos agora na prática um fluxo de trabalho com <code>sklearn</code> de ponta a ponta e nos aprofundaremos um pouco mais em cada etapa no decorrer dos estudos.</p>
<p>Nesse capítulo vamos explorar um problema de classificação binária ou seja (<em>uma amostra só poder ser uma coisa ou outra</em>). O conjunto de dados que usaremos é o mesmo do capítulo de Matplotlib (<em>uma lista de pacientes anônimos e se eles possuem ou não doenças cardíacas</em>).</p>
<p>Vamos começar importando algumas bibliotecas e carregando os dados:</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

df = pd.read_csv(<span class="hljs-string">&quot;heart-disease.csv&quot;</span>)
df.head()
</code></pre>
<p><img src="images/sklearn-1.png" alt="heart disease df"></p>
<h2 id="eda">EDA</h2>
<p>Uma vez que importamos os dados, a próxima etapa é explorar. Não há uma maneira definitiva para fazer isso. O objetivo é se familiarizar cada vez mais com os dados. Podemos começar verificando quantas vezes cada um dos valores de uma coluna categórica aparece, no caso vamos inspecionar a coluna <code>target</code> utilizando a função <code>value_counts()</code> do Pandas:</p>
<pre><code class="lang-python">df[<span class="hljs-string">&quot;target&quot;</span>].value_counts()

<span class="hljs-number">1</span>    <span class="hljs-number">165</span>
<span class="hljs-number">0</span>    <span class="hljs-number">138</span>
Name: target, dtype: int64
</code></pre>
<p>Outra opção é visualizar esses valores em porcentagens, o <code>value_counts()</code> recebe um parâmetro chamado <code>normalize</code> que pode ser definido como <code>True</code>:</p>
<pre><code class="lang-python">df[<span class="hljs-string">&quot;target&quot;</span>].value_counts(normalize=<span class="hljs-literal">True</span>)

<span class="hljs-number">1</span>    <span class="hljs-number">0.544554</span>
<span class="hljs-number">0</span>    <span class="hljs-number">0.455446</span>
Name: target, dtype: float64
</code></pre>
<p>Podemos também plotar esses valores:</p>
<pre><code class="lang-python">df[<span class="hljs-string">&quot;target&quot;</span>].value_counts().plot(kind=<span class="hljs-string">&quot;bar&quot;</span>, color=[<span class="hljs-string">&quot;salmon&quot;</span>, <span class="hljs-string">&quot;lightblue&quot;</span>]);
</code></pre>
<p><img src="images/sklearn-plot-1.png" alt="plot target value counts"></p>
<p>Vamos verificar os valores ausentes que podem existir e os tipos de dados com que vamos trabalhar:</p>
<pre><code>df.info()

&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;
RangeIndex: 303 entries, 0 to 302
Data columns (total 14 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   age       303 non-null    int64  
 1   sex       303 non-null    int64  
 2   cp        303 non-null    int64  
 3   trestbps  303 non-null    int64  
 4   chol      303 non-null    int64  
 5   fbs       303 non-null    int64  
 6   restecg   303 non-null    int64  
 7   thalach   303 non-null    int64  
 8   exang     303 non-null    int64  
 9   oldpeak   303 non-null    float64
 10  slope     303 non-null    int64  
 11  ca        303 non-null    int64  
 12  thal      303 non-null    int64  
 13  target    303 non-null    int64  
dtypes: float64(1), int64(13)
memory usage: 33.3 KB
</code></pre><blockquote>
<p>Felizmente nesse caso não temos valores ausentes e todas as colunas são de natureza numérica.</p>
</blockquote>
<h2 id="frequência-de-doenças-cardíacas-de-acordo-com-o-sexo">Frequência de doenças cardíacas de acordo com o sexo</h2>
<p>Mais uma análise interessante que podemos fazer é verificar a frequência das doenças cardíacas de acordo com o sexo. Para comparar duas colunas entre si, podemos utilizar a função <code>pd.crosstab(coluna_1, coluna_2)</code>. Vamos comparar a coluna <code>target</code> com a coluna <code>sex</code>:</p>
<pre><code class="lang-python">pd.crosstab(df[<span class="hljs-string">&quot;target&quot;</span>], df[<span class="hljs-string">&quot;sex&quot;</span>])
</code></pre>
<table>
<thead>
<tr>
<th style="text-align:center">sex</th>
<th style="text-align:center">0</th>
<th style="text-align:center">1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">target</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">0</td>
<td style="text-align:center">24</td>
<td style="text-align:center">114</td>
</tr>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">72</td>
<td style="text-align:center">93</td>
</tr>
</tbody>
</table>
<p>Existem cerca de 100 mulheres e 72 delas têm um valor positivo de presença de alguma doença cardíaca, podemo inferi com base nessa variável, se a participante for mulher, há 75% de chance de ela ter uma doença cardíaca.</p>
<p>Quanto aos homens, há cerca de 200 no total, com quase metade indicando a presença de doenças cardíacas. Assim podemos prever que, se o participante for do sexo masculino, 50% das vezes ele terá uma doença cardíaca.</p>
<p>Aplicando a média desses dois valores, podemos supor, com base em nenhum outro parâmetro, caso haja uma pessoa, há 62,5% de chance de que ela tenha uma doença cardíaca.</p>
<blockquote>
<p>Esse pode ser nosso baseline, tentaremos vencê-lo com Machine Learning.</p>
</blockquote>
<p>O exemplo utilizando <code>crosstab</code> poderia ficar melhor em um gráfico, vamos plotar utilizando alguns parâmetros na função <code>plot()</code> e adicionar alguns atributos explicativos:</p>
<pre><code class="lang-python"><span class="hljs-comment"># Criando o plot</span>
pd.crosstab(df.target, df.sex).plot(kind=<span class="hljs-string">&quot;bar&quot;</span>,
                                    figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">6</span>),
                                    color=[<span class="hljs-string">&quot;salmon&quot;</span>, <span class="hljs-string">&quot;lightblue&quot;</span>])

<span class="hljs-comment"># Adicionando atributos</span>
plt.title(<span class="hljs-string">&quot;Frequência de doenças cardíacas por sexo&quot;</span>)
plt.xlabel(<span class="hljs-string">&quot;0 = Não tem doença, 1 = Doença detectada&quot;</span>)
plt.ylabel(<span class="hljs-string">&quot;Montante&quot;</span>)
plt.legend([<span class="hljs-string">&quot;Mulher&quot;</span>, <span class="hljs-string">&quot;Homen&quot;</span>])
plt.xticks(rotation=<span class="hljs-number">0</span>); <span class="hljs-comment"># configura os eixos dos labels para vertical</span>
</code></pre>
<p><img src="images/sklearn-plot-2.png" alt="plot target sex crosstab"></p>
<h2 id="idade-vs-frequência-cardíaca-máxima-para-doenças-cardíacas">Idade vs Frequência cardíaca máxima para doenças cardíacas</h2>
<p>Vamos tentar combinar outras duas variáveis, como idade e <code>thalach</code> (<em>frequência cardíaca máxima</em>) e depois compará-las com a variável <code>target</code>. Como temos muitos valores para as duas variáveis, vamos plotar usando um gráfico do tipo <code>scatter</code>.</p>
<pre><code class="lang-python">plt.figure(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">6</span>))

<span class="hljs-comment"># Plot para valores positivos</span>
plt.scatter(df[<span class="hljs-string">&quot;age&quot;</span>][df[<span class="hljs-string">&quot;target&quot;</span>] ==<span class="hljs-number">1</span> ], 
            df[<span class="hljs-string">&quot;thalach&quot;</span>][df[<span class="hljs-string">&quot;target&quot;</span>] == <span class="hljs-number">1</span>], 
            c=<span class="hljs-string">&quot;salmon&quot;</span>)

<span class="hljs-comment"># Plot para valores negativos</span>
<span class="hljs-comment"># queremos plotar no mesmo gráfico então não vamos configurar axes diferentes</span>
plt.scatter(df[<span class="hljs-string">&quot;age&quot;</span>][df[<span class="hljs-string">&quot;target&quot;</span>] == <span class="hljs-number">0</span>], 
            df[<span class="hljs-string">&quot;thalach&quot;</span>][df[<span class="hljs-string">&quot;target&quot;</span>] == <span class="hljs-number">0</span>], 
            c=<span class="hljs-string">&quot;lightblue&quot;</span>)

<span class="hljs-comment"># Atributos</span>
plt.title(<span class="hljs-string">&quot;Doença cardíaca em função da idade e da frequência cardíaca máxima&quot;</span>)
plt.xlabel(<span class="hljs-string">&quot;Idade&quot;</span>)
plt.legend([<span class="hljs-string">&quot;Doença detectada&quot;</span>, <span class="hljs-string">&quot;Não tem doença&quot;</span>])
plt.ylabel(<span class="hljs-string">&quot;Frequência cardíaca máxima&quot;</span>);
</code></pre>
<p><img src="images/sklearn-plot-3.png" alt="plot target age scatter"></p>
<p>Parece que quanto mais jovem alguém é, maior sua frequência cardíaca máxima (<em>são os pontos mais altos à esquerda do gráfico</em>) e quanto mais velho alguém é, mais pontos azuis existem. Mas isso pode ser porque há mais pontos juntos no lado direito do gráfico (<em>indica participantes mais velhos</em>).</p>
<h2 id="frequência-de-doenças-cardíacas-por-tipo-de-dor-torácica">Frequência de Doenças Cardíacas por Tipo de Dor Torácica</h2>
<p>Vamos tentar analisar outra variável. Desta vez <code>cp</code> (<em>dor no peito</em>), utilizaremos o mesmo processo de antes:</p>
<pre><code class="lang-python">pd.crosstab(df[<span class="hljs-string">&quot;cp&quot;</span>], df[<span class="hljs-string">&quot;target&quot;</span>]).plot(kind=<span class="hljs-string">&quot;bar&quot;</span>, 
                                   figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">6</span>), 
                                   color=[<span class="hljs-string">&quot;lightblue&quot;</span>, <span class="hljs-string">&quot;salmon&quot;</span>])

<span class="hljs-comment"># Adicionando atributos ao gráfico</span>
plt.title(<span class="hljs-string">&quot;Frequência de Doença Cardíaca por Tipo de Dor Torácica&quot;</span>)
plt.xlabel(<span class="hljs-string">&quot;Tipo de dor no peito&quot;</span>)
plt.ylabel(<span class="hljs-string">&quot;Frequência&quot;</span>)
plt.legend([<span class="hljs-string">&quot;Não tem doença&quot;</span>, <span class="hljs-string">&quot;Doença detectada&quot;</span>])
plt.xticks(rotation = <span class="hljs-number">0</span>);
</code></pre>
<p><img src="images/sklearn-plot-4.png" alt="plot target cp bar"></p>
<p>Antes de prosseguir, precisamos de um pequeno dicionário:</p>
<ul>
<li><strong>cp</strong>  (<em>dor no peito</em>)</li>
<li><strong>0</strong>   (<em>típica dor no peito</em>)</li>
<li><strong>1</strong>   (<em>dor no peito, não relacionada ao coração</em>)</li>
<li><strong>2</strong>   (<em>espasmos, não relacionados ao coração</em>)</li>
<li><strong>3</strong>   (<em>dor torácica, sem sinais de doença</em>)</li>
</ul>
<p>É interessante notar que o valor <code>1</code> afirma que a dor não está relacionada ao coração, mas parece ter uma proporção maior de participantes com doenças cardíacas.</p>
<blockquote>
<p>De acordo com o PubMed, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2763472/" target="_blank">parece que até alguns profissionais médicos estão confusos com o termo</a>.</p>
</blockquote>
<p>Embora não conclusivo, o gráfico acima é uma alerta que revela a confusão das definições apresentadas nos dados.</p>
<h2 id="correlação-entre-variáveis-independentes">Correlação entre variáveis independentes</h2>
<p>Por fim, vamos comparar todas as variáveis independentes, plotando em um único resultado. Isso pode nos dar uma ideia de quais variáveis independentes podem ou não ter impacto na nossa variável <code>target</code>.</p>
<p>Para fazer isso podemos usar <code>df.corr()</code> que cria uma matriz de correlação, uma grande tabela de números informando o quanto cada variável está relacionada à outra.</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns

corr_matrix = df.corr()
plt.figure(figsize=(<span class="hljs-number">15</span>, <span class="hljs-number">10</span>))
sns.heatmap(corr_matrix, 
            annot=<span class="hljs-literal">True</span>, 
            linewidths=<span class="hljs-number">0.5</span>, 
            fmt= <span class="hljs-string">&quot;.2f&quot;</span>, 
            cmap=<span class="hljs-string">&quot;YlGnBu&quot;</span>);
</code></pre>
<p><img src="images/sklearn-plot-matrix.png" alt="sklearn plot matrix corr"></p>
<blockquote>
<p>Não se preocupe com a biblioteca <code>seaborn</code> utilizada neste exemplo, falaremos mais sobre ela <em>Apêndice A</em>.</p>
</blockquote>
<p>Um valor positivo mais alto significa um potencial para uma correlação positiva e um valor negativo mais alto, significa um potencial para uma correlação negativa.</p>
<h2 id="modelagem-dos-dados">Modelagem dos dados</h2>
<p>Exploramos os dados e agora tentaremos utilizar <code>ML</code> para prever nossa variável <code>target</code> com base nas outras 13 variáveis independentes. Antes de construir um modelo é preciso preparar os dados.</p>
<p>Relembrando, cada linha do DataFrame é um paciente diferente, todas as colunas, exceto <code>target</code> são características dos pacientes. O <code>target</code> indica se o paciente tem doença cardíaca (<code>target=1</code>) ou não (<code>target=0</code>). Em outras palavras, estamos tentando prever o valor da nossa variável <code>target</code> usando todas as outras variáveis. Para fazer isso com <code>sklearn</code> precisamos separar a variável <code>target</code> de todo o resto:</p>
<pre><code class="lang-python">X = df.drop(<span class="hljs-string">&quot;target&quot;</span>, axis=<span class="hljs-number">1</span>)
y = df[<span class="hljs-string">&quot;target&quot;</span>]

X.head()
</code></pre>
<p><img src="images/sklearn-2.png" alt="heart disease target"></p>
<pre><code>y.head()

0    1
1    1
2    1
3    1
4    1
Name: target, dtype: int64
</code></pre><p>O que fizemos aqui foi isolar a coluna <code>target</code> na variável <code>y</code> e manter todas as outras colunas na variável <code>X</code>. A utilização de <code>X</code> e <code>y</code> como variáveis são um padrão adotado pelos desenvolvedores (<em>bastante comum nos exemplos que você vai encontrar em outros livros, cursos e repositórios</em>).</p>
<h2 id="treino-e-teste">Treino e Teste</h2>
<p>Chegou o momento de dividir os dados em um conjunto para treino e um conjunto para teste. Esse é um dos conceitos mais importantes em <code>ML</code>.</p>
<p>Utilizaremos o conjunto de treino para treinar o nosso modelo (<em>são os dados que o modelo utiliza para aprender</em>) e o conjunto de testes para testá-lo (<em>são os dados utilizados para validar o modelo</em>).</p>
<blockquote>
<p>O conjunto de testes sempre deve permanecer separado do conjunto de treinamento!</p>
</blockquote>
<p>E por que não usar todos os dados para treinar um modelo ? Digamos que você queira usar o seu modelo em uma aplicação real de hospital, classificando os pacientes. Como você saberia o desempenho do seu modelo em um novo paciente não incluído no conjunto de dados inicial que você tinha ? E é aqui que entra o conjunto de teste. Ele é usado para simular o máximo possível a utilização do modelo em um ambiente real.</p>
<p>Para dividir nossos dados em dois conjuntos, um de treinamento e outro de teste, podemos usar o <code>train_test_split()</code> do <code>sklearn</code> e alimentá-lo com nossas variáveis (<code>X</code> e <code>y</code>):</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split

np.random.seed(<span class="hljs-number">42</span>)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="hljs-number">0.2</span>)

X_train.head()
</code></pre>
<p><img src="images/sklearn-3.png" alt="heart disease split"></p>
<blockquote>
<p>Note o <code>seed</code> do NumPy em ação, essa configuração serve para preservar o estado do que faremos aqui, em outras palavras os resultados que você vai ver nos exemplos serão os mesmos no seu ambiente na hora de reproduzir.</p>
</blockquote>
<p>O parâmetro <code>test_size</code> é utilizado para informar à função <code>train_test_split()</code> quanto de nossos dados queremos no conjunto de teste. Nesse caso, <code>0.2</code> que representa <code>20%</code>. Uma regra prática é utilizar <code>80%</code> dos seus dados para treino e os outros <code>20%</code> para teste.</p>
<p>Para o nosso exemplo, um conjunto de treino e teste são suficientes. Mas para outros problemas, você também pode precisar de um conjunto de validação (<em>treinar, validar e testar</em>).</p>
<h3 id="escolha-de-modelos">Escolha de modelos</h3>
<p>Agora que os dados estão preparados, podemos começar a treinar os modelos. Vamos utilizar e comparar os resultados dos respectivos modelos:</p>
<ul>
<li><strong>Logistic Regression</strong> - <code>LogisticRegression()</code></li>
<li><strong>K-Nearest Neighbors</strong> - <code>KNeighboursClassifier()</code></li>
<li><strong>RandomForest</strong> - <code>RandomForestClassifier()</code></li>
</ul>
<p>Ok, mas por que esses ? O <code>Scikit-Learn</code> disponibiliza um <a href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html" target="_blank">mapa que podemos seguir</a> para fazer as escolhas do que utilizar como solução para o nosso problema.</p>
<p>Vejamos como fica o nosso problema:</p>
<p><img src="images/ml_map.png" alt="ml sklearn map"></p>
<blockquote>
<p>Eu não sei porque <code>Logistic Regression</code> não é listado no mapa, pois ao ler a documentação do <code>Scikit-Learn</code> sobre esse tipo de modelo, consta que é um modelo para classificação.</p>
</blockquote>
<p><code>LinearSVC</code>, vamos ignorar, fingir que tentamos e não funcionou, então estamos seguindo para as outras opções no mapa. No momento, conhecer cada um desses algoritmos a fundo não é essencial. Machine Learning e Data Science são uma prática iterativa, esses algoritmos são ferramentas para o seu arsenal. Nesse momento, para se tornar um bom praticante, é mais importante entender o problema que queremos resolver (<em>classificação</em> vs <em>regressão</em>) e depois avaliar quais ferramentas utilizar para resolver os problemas.</p>
<p>Como o nosso conjunto de dados é relativamente pequeno (<em>303 amostras</em>), podemos experimentar para encontrar o algoritmo que oferece o melhor desempenho.</p>
<p>Todos os algoritmos disponíveis na <code>sklearn</code> usam as mesmas funções para treinar um modelo <code>model.fit(X_train, y_train)</code> e para saber se um modelo é efetivo ou não usa a função <code>model.score(X_test, y_test)</code> que retorna a proporção de previsões corretas (<em>1.0 = 100%</em>).</p>
<p>Como os algoritmos que escolhemos implementam os mesmos métodos para treinar e avaliar, vamos colocá-los em um dicionário e desenvolver um modelo que treine com cada um deles e classifique os dados.</p>
<pre><code class="lang-python"><span class="hljs-comment"># imports</span>
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression
<span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier
<span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForestClassifier
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># inserindo os algoritmos em um dicionário</span>
models = {<span class="hljs-string">&quot;KNN&quot;</span>: KNeighborsClassifier(),
           <span class="hljs-string">&quot;Logistc Regression&quot;</span>: LogisticRegression(),
           <span class="hljs-string">&quot;Random Forest&quot;</span>: RandomForestClassifier()}

<span class="hljs-comment"># criando uma função para treinar e avaliar os modelos</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit_and_score</span>(<span class="hljs-params">models, X_train, X_test, y_train, y_test</span>):</span>

  <span class="hljs-comment"># seed para ter resultados reproduzíveis</span>
  np.random.seed(<span class="hljs-number">42</span>)

  <span class="hljs-comment"># criando uma lista para armazenar o score dos modelos</span>
  model_scores = {}

  <span class="hljs-comment"># loop para executar todos os modelos</span>
  <span class="hljs-keyword">for</span> name, model <span class="hljs-keyword">in</span> models.items():

    <span class="hljs-comment"># treina o modelo com os dados</span>
    model.fit(X_train, y_train)

    <span class="hljs-comment"># Avalia o modelo e adiciona seu score na lista</span>
    model_scores[name] = model.score(X_test, y_test)

  <span class="hljs-keyword">return</span> model_scores
</code></pre>
<pre><code class="lang-python"><span class="hljs-comment"># executando a função</span>
model_scores = fit_and_score(models=models,
                             X_train=X_train,
                             X_test=X_test,
                             y_train=y_train,
                             y_test=y_test)
model_scores

{<span class="hljs-string">&apos;KNN&apos;</span>: <span class="hljs-number">0.6885245901639344</span>,
 <span class="hljs-string">&apos;Logistc Regression&apos;</span>: <span class="hljs-number">0.8524590163934426</span>,
 <span class="hljs-string">&apos;Random Forest&apos;</span>: <span class="hljs-number">0.8360655737704918</span>}
</code></pre>
<p>Olhando para os valores, parece que o modelo <code>LogisticRegression()</code> tem o melhor desempenho. O próximo passo é ajustar os hiperparâmetros dos modelos (<em>configurações refinadas</em>) e avaliar novamente para ver se o ajuste influencia no <code>score</code>.</p>
<h2 id="ajuste-de-hiperparâmetros-e-validação-cruzada">Ajuste de hiperparâmetros e validação cruzada</h2>
<p>Imagine que para fazer uma pizza você ajusta o forno para 180 graus. Mas quando um amigo vai utilizar o mesmo forno para preparar uma pizza, ele utiliza em 200 graus. Temos o mesmo forno, com configurações diferentes, logo teremos resultados diferentes.</p>
<p>O mesmo pensamento pode ser aplicado em <code>ML</code>, podemos utilizar os mesmos algoritmos, aplicando pequenas configurações (<em>hiperparâmetros</em>) e obter resultados diferentes. Assim como ajustar o forno para aquecer mais pode queimar a comida, o mesmo ocorre com os algoritmos de <code>ML</code>. Podemos ajustar as configurações para funcionar tão bem que <em>superajusta</em> os dados.</p>
<p>Queremos encontrar um meio termo, um modelo que se saia bem com o nosso conjunto de dados, mas também que entregue bons resultados em exemplos nunca vistos.</p>
<p>Para testar diferentes hiperparâmetros, podemos utilizar um conjunto de dados de validação, o problema é que não temos muitos dados, então usaremos validação cruzada. O tipo mais utilizado de validação cruzada é o <code>K-fold</code>, basicamente funciona dividindo os dados em grupos menores e, em seguida, testa um modelo em cada um dos grupos. Por exemplo, se tivéssemos 5 <code>folds</code> (k=5):</p>
<p><img src="images/k-fold.png" alt="k-fold"></p>
<p>Vamos utilizar essa configuração para ajustar os hiperparâmetros de alguns dos modelos que treinamos e depois vamos avaliá-los.</p>
<h2 id="ajustando-kneighborsclassifier-knn">Ajustando KNeighborsClassifier (KNN)</h2>
<p>Existe um hiperparâmetro principal que podemos ajustar para o algoritmo <code>KNN</code>, trata-se do número de vizinhos. Por padrão esse valor é 5 (<code>n_neigbors=5</code>).</p>
<p>Ok, mas o que são esses &quot;vizinhos&quot; ? Imagine todos os dados que plotamos anteriormente em um gráfico do tipo <code>scatter</code>. O algoritmos <code>KNN</code> analisa se os pontos mais próximos pertencem à mesma classe. Ou seja se <code>n_neigbors=5</code> então <code>KNN</code> assume que os 5 pontos mais próximos ao seu redor estão na mesma classe. O nosso plano no momento é tentar alguns valores diferentes para <code>n_neigbors</code>.</p>
<pre><code class="lang-python"><span class="hljs-comment"># Lista para armazenar o score de treino</span>
train_scores = []

<span class="hljs-comment"># Lista para armazenar o score de teste</span>
test_scores = []

<span class="hljs-comment"># Lista com diferentes valores para &quot;n_neighbors&quot;</span>
<span class="hljs-comment"># vamos começar com 1 e subir até 20</span>
neighbors = <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">21</span>)

<span class="hljs-comment"># Instanciando o KNN</span>
knn = KNeighborsClassifier()

<span class="hljs-comment"># Loop para aplicar os diferentes valores em &quot;n_neighbors&quot;</span>
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> neighbors:
    knn.set_params(n_neighbors = i)

    <span class="hljs-comment"># Treina o modelo</span>
    knn.fit(X_train, y_train)

    <span class="hljs-comment"># Guarda o score de treino</span>
    train_scores.append(knn.score(X_train, y_train))

    <span class="hljs-comment"># Armazena o score de teste</span>
    test_scores.append(knn.score(X_test, y_test))
</code></pre>
<p>Agora vamos dar uma olhada nos scores de treino para ver qual ajuste tem melhor performance:</p>
<pre><code class="lang-python">train_scores

[<span class="hljs-number">1.0</span>,
 <span class="hljs-number">0.8099173553719008</span>,
 <span class="hljs-number">0.7727272727272727</span>,
 <span class="hljs-number">0.743801652892562</span>,
 <span class="hljs-number">0.7603305785123967</span>,
 <span class="hljs-number">0.7520661157024794</span>,
 <span class="hljs-number">0.743801652892562</span>,
 <span class="hljs-number">0.7231404958677686</span>,
 <span class="hljs-number">0.71900826446281</span>,
 <span class="hljs-number">0.6942148760330579</span>,
 <span class="hljs-number">0.7272727272727273</span>,
 <span class="hljs-number">0.6983471074380165</span>,
 <span class="hljs-number">0.6900826446280992</span>,
 <span class="hljs-number">0.6942148760330579</span>,
 <span class="hljs-number">0.6859504132231405</span>,
 <span class="hljs-number">0.6735537190082644</span>,
 <span class="hljs-number">0.6859504132231405</span>,
 <span class="hljs-number">0.6652892561983471</span>,
 <span class="hljs-number">0.6818181818181818</span>,
 <span class="hljs-number">0.6694214876033058</span>]
</code></pre>
<p>Péssima ideia tentar entender esses valores, melhor criarmos um gráfico, vamos ao plot:</p>
<pre><code class="lang-python">plt.plot(neighbors, train_scores, label=<span class="hljs-string">&quot;Score de Treino&quot;</span>)
plt.plot(neighbors, test_scores, label=<span class="hljs-string">&quot;Score de Teste&quot;</span>)
plt.xticks(np.arange(<span class="hljs-number">1</span>, <span class="hljs-number">21</span>, <span class="hljs-number">1</span>))
plt.xlabel(<span class="hljs-string">&quot;Valor ajustado para n_neighbors&quot;</span>)
plt.ylabel(<span class="hljs-string">&quot;Desempenho do modelo&quot;</span>)
plt.legend()

<span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Desempenho máximo de KNN nos dados de teste: <span class="hljs-subst">{<span class="hljs-built_in">max</span>(test_scores)*<span class="hljs-number">100</span>:<span class="hljs-number">.2</span>f}</span>%&quot;</span>)
</code></pre>
<p><strong>Desempenho máximo de KNN nos dados de teste: 75.41%</strong></p>
<p><img src="images/knn-1.png" alt="knn desempenho"></p>
<p>No gráfico, a configuração <code>n_neighbors=11</code> apresenta o melhor resultado. Mesmo ajustando esse hiperparâmetro o desempenho do modelo <code>KNN</code> não chegou nem perto do resultado de <code>LogisticRegression</code> ou de <code>RandomForestClassifier</code>. Por esse motivo, vamos descartar o <code>KNN</code> e focar nos outros dois que tiveram melhor resultado.</p>
<p>No exemplo de <code>KNN</code> ajustamos o hiperparâmetro manualmente, em vez de fazer isso com <code>LogisticRegression</code> e <code>RandomForest</code>, veremos como automatizar utilizando <code>RandomizedSearchCV</code>, basicamente esse recurso tenta várias combinações diferentes, avalia todas e salva a melhor.</p>
<h2 id="ajustando-modelos-com-randomizedsearchcv">Ajustando modelos com RandomizedSearchCV</h2>
<p>A documentação do <code>sklearn</code> mostra que há vários hiperparâmetros diferentes que podemos ajustar para <code>LogisticRegression</code>. O mesmo vale para <code>RandomForest</code>. Vamos implementar um dicionário com diferentes hiperparâmetros para cada um dos algoritmos e depois testá-los:</p>
<pre><code class="lang-python"><span class="hljs-comment"># LogisticRegression hiperparâmetros</span>
log_reg_grid = {<span class="hljs-string">&quot;C&quot;</span>: np.logspace(-<span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">20</span>),
                <span class="hljs-string">&quot;solver&quot;</span>: [<span class="hljs-string">&quot;liblinear&quot;</span>]}

<span class="hljs-comment"># RandomForestClassifier hiperparâmetros</span>
rf_grid = {<span class="hljs-string">&quot;n_estimators&quot;</span>: np.arange(<span class="hljs-number">10</span>, <span class="hljs-number">1000</span>, <span class="hljs-number">50</span>),
           <span class="hljs-string">&quot;max_depth&quot;</span>: [<span class="hljs-literal">None</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">10</span>],
           <span class="hljs-string">&quot;min_samples_split&quot;</span>: np.arange(<span class="hljs-number">2</span>, <span class="hljs-number">20</span>, <span class="hljs-number">2</span>),
           <span class="hljs-string">&quot;min_samples_leaf&quot;</span>: np.arange(<span class="hljs-number">1</span>, <span class="hljs-number">20</span>, <span class="hljs-number">2</span>)}
</code></pre>
<p>Agora, utilizando o <code>RandomizedSearchCV</code>, vamos tentar ajustar nosso modelo <code>LogisticRegression</code>. Precisamos informar os diferentes hiperparâmetros de <code>log_reg_grid</code> e definir <code>n_iter=20</code>. Em outras palavras <code>RandomizedSearchCV</code> vai trabalhar com 20 combinações diferentes de hiperparâmetros e salvará apenas as melhores.</p>
<pre><code class="lang-python"><span class="hljs-comment"># Import</span>
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> RandomizedSearchCV, GridSearchCV

<span class="hljs-comment"># Definindo o seed</span>
np.random.seed(<span class="hljs-number">42</span>)

<span class="hljs-comment"># Configurando hiperparâmetros para LogisticRegression</span>
rs_log_reg = RandomizedSearchCV(LogisticRegression(),
                                param_distributions=log_reg_grid,
                                cv=<span class="hljs-number">5</span>,
                                n_iter=<span class="hljs-number">20</span>,
                                verbose=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># Treinando o modelo com as 20 combinações possíveis</span>
rs_log_reg.fit(X_train, y_train);
</code></pre>
<blockquote>
<p>Fitting 5 folds for each of 20 candidates, totalling 100 fits</p>
</blockquote>
<p>Agora podemos verificar qual foi o score obtido no treino e qual foi a melhor combinação de hiperparâmetro encontrada:</p>
<pre><code class="lang-python">rs_log_reg.score(X_test, y_test)

<span class="hljs-number">0.8852459016393442</span>

rs_log_reg.best_params_

{<span class="hljs-string">&apos;C&apos;</span>: <span class="hljs-number">0.23357214690901212</span>, <span class="hljs-string">&apos;solver&apos;</span>: <span class="hljs-string">&apos;liblinear&apos;</span>}
</code></pre>
<p>Agora que ajustamos <code>LogisticRegression</code>, faremos o mesmo com <code>RandomForest</code>:</p>
<pre><code class="lang-python"><span class="hljs-comment"># Definindo o seed</span>
np.random.seed(<span class="hljs-number">42</span>)

<span class="hljs-comment"># Configurando hiperparâmetros para RandomForestClassifier</span>
rs_rf = RandomizedSearchCV(RandomForestClassifier(),
                           param_distributions=rf_grid,
                           cv=<span class="hljs-number">5</span>,
                           n_iter=<span class="hljs-number">20</span>,
                           verbose=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># Treinando o modelo com as 20 combinações possíveis</span>
rs_rf.fit(X_train, y_train);
</code></pre>
<blockquote>
<p>Fitting 5 folds for each of 20 candidates, totalling 100 fits</p>
</blockquote>
<p>Verificando o score e a melhor combinação:</p>
<pre><code class="lang-python">rs_rf.best_params_

{<span class="hljs-string">&apos;max_depth&apos;</span>: <span class="hljs-number">3</span>,
 <span class="hljs-string">&apos;min_samples_leaf&apos;</span>: <span class="hljs-number">19</span>,
 <span class="hljs-string">&apos;min_samples_split&apos;</span>: <span class="hljs-number">4</span>,
 <span class="hljs-string">&apos;n_estimators&apos;</span>: <span class="hljs-number">210</span>}

rs_rf.score(X_test, y_test)

<span class="hljs-number">0.8688524590163934</span>
</code></pre>
<p>Com os ajustes nos modelos tivemos um leve aumento no desempenho em <code>RandomForrestClassifier</code> e <code>LogisticRegression</code>. Mesmo com <code>LogisticRegression</code> ganhando, vamos tentar ajustá-lo ainda mais com <code>GridSearchCV</code>.</p>
<h2 id="ajustando-modelos-com-gridsearchcv">Ajustando modelos com GridSearchCV</h2>
<p>A principal diferença entre <code>RandomizedSearchCV</code> e <code>GridSearchCV</code> é que o primeiro pesquisa em um dicionário de hiperparâmetros executando várias combinações definidas em <code>n_iter</code>, enquanto o segundo testará <em>todas</em> as combinações possíveis.</p>
<p>Na prática:</p>
<pre><code class="lang-python">log_reg_grid = {<span class="hljs-string">&quot;C&quot;</span>: np.logspace(-<span class="hljs-number">4</span>, <span class="hljs-number">4</span>, <span class="hljs-number">20</span>),
                <span class="hljs-string">&quot;solver&quot;</span>: [<span class="hljs-string">&quot;liblinear&quot;</span>]}

gs_log_reg = GridSearchCV(LogisticRegression(),
                          param_grid=log_reg_grid,
                          cv=<span class="hljs-number">5</span>,
                          verbose=<span class="hljs-literal">True</span>)

gs_log_reg.fit(X_train, y_train);
</code></pre>
<blockquote>
<p>Fitting 5 folds for each of 20 candidates, totalling 100 fits</p>
</blockquote>
<pre><code class="lang-python">gs_log_reg.best_params_

{<span class="hljs-string">&apos;C&apos;</span>: <span class="hljs-number">0.23357214690901212</span>, <span class="hljs-string">&apos;solver&apos;</span>: <span class="hljs-string">&apos;liblinear&apos;</span>}

gs_log_reg.score(X_test, y_test)

<span class="hljs-number">0.8852459016393442</span>
</code></pre>
<p>Nesse caso, tivemos os mesmos resultados de antes pois nosso dicionário de opções tem no máximo 20 combinações de hiperparâmetros diferentes. Se por acaso houver uma grande quantidade de combinações de hiperparâmetros em seu dicionário, o <code>GridSearchCV</code> levará muito tempo para testar todas as opções. Por isso é recomendado começar com <code>RandomizedSearchCV</code> e tentar com uma quantidade menor de combinações.</p>
<h2 id="avaliando-um-modelo-de-classificação">Avaliando um modelo de classificação</h2>
<p>Agora que o nosso modelo está ajustado, vamos analisar algumas métricas. Para isso, teremos que utilizar o modelo para fazer previsões no nosso conjunto de teste. As previsões podem ser feitas pelo método <code>predict()</code> em um modelo treinado, passando a ele os dados que desejamos <em>prever</em>.</p>
<p>As previsões serão feitas nos dados de teste:</p>
<pre><code class="lang-python">y_preds = gs_log_reg.predict(X_test)
</code></pre>
<p>Agora que temos nossos valores de previsão armazenados em <code>y_preds</code>, podemos focar nas métricas.</p>
<h2 id="roc-curve-e-auc-scores">ROC Curve e AUC Scores</h2>
<p><em>ROC o que ?</em> É uma forma de entender o desempenho do nosso modelo, comparando a taxa de verdadeiros positivos com a taxa de falsos positivos.
Ou seja, para o nosso problema, pense em um teste de diagnóstico que verifica se uma pessoa tem uma doença cardíaca. Um falso positivo nesse caso ocorre quando a pessoa testa positivo, mas na verdade não tem a doença. E um falso negativo, ocorre quando a pessoa tem um resultado de teste negativo, sugerindo que está saudável, quando na verdade tem a doença.</p>
<p>Ficou imaginando como fazer essas verificações nos dados ? Pois bem, felizmente <code>Scikit-Learn</code> implementa uma função chamada <code>plot_roc_curve</code> que pode ajudar na criação dessa métrica.</p>
<p>A funçào <code>plot_roc_curve</code> recebe como entrada <code>(estimator, X, y)</code>, onde <code>estimator</code> é um modelo de <code>ML</code> ajustado (<em>o nosso modelo treinado anteriormente</em>) e <code>X</code> e <code>y</code> são os dados que queremos testar. Usaremos a última versão do nosso modelo <code>LogisticRegression</code> como <code>estimator</code> e os dados teste (<code>X_test</code> e <code>y_test</code>).</p>
<pre><code class="lang-python"><span class="hljs-comment"># Import ROC Curve</span>
<span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> plot_roc_curve

<span class="hljs-comment"># Plot ROC Curve e calcula a métrica</span>
plot_roc_curve(gs_log_reg, X_test, y_test);
</code></pre>
<p><img src="images/roc-curve.png" alt="plot roc curve"></p>
<p>Olhando para esse plot pode parecer um pouco confuso. A principal coisa que podemos observar aqui é que o modelo está se saindo muito melhor do que apenas <em>adivinhar</em>. A métrica usada para quantificar a <code>ROC Curve</code> se chama <code>AUC</code>.</p>
<p>A pontuação máxima dessa métrica que podemos alcançar é <code>1,0</code> e, geralmente quanto mais próximo de <code>1,0</code> melhor o modelo. A posição mais ideal para essa curva em azul seria ao longo do canto superior esquerdo do gráfico. Isso significaria que o modelo consegue prever apenas <em>verdadeiros positivos</em> e nenhum <em>falso positivo</em>.</p>
<p>Vamos agora para a próxima métrica de avaliação, <em>Matriz de Confusão</em>.</p>
<h2 id="matriz-de-confusão">Matriz de Confusão</h2>
<p>Uma Matriz de Confusão é uma forma de visualizar onde o modelo fez as previsões certas e onde fez as erradas em outras palavras (<em>onde ele ficou confuso</em>). O <code>sklearn</code> por meio da função <code>confusion_matrix()</code> nos permite criar essa matriz, passando os rótulos verdadeiros e os previstos.</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> confusion_matrix, classification_report
<span class="hljs-built_in">print</span>(confusion_matrix(y_test, y_preds))
</code></pre>
<blockquote>
<p>Ok, essa matriz de confusão embutida do <code>sklearn</code> é sem graça. Vamos melhorar esse visual.</p>
</blockquote>
<pre><code class="lang-python"><span class="hljs-comment"># Seaborn</span>
<span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns
sns.<span class="hljs-built_in">set</span>(font_scale=<span class="hljs-number">1.5</span>)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_conf_mat</span>(<span class="hljs-params">y_test, y_preds</span>):</span>
    fig, ax = plt.subplots(figsize=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))
    ax = sns.heatmap(confusion_matrix(y_test, y_preds),
                     annot=<span class="hljs-literal">True</span>,
                     cbar=<span class="hljs-literal">False</span>)
    plt.xlabel(<span class="hljs-string">&quot;rótulos verdadeiros&quot;</span>)
    plt.ylabel(<span class="hljs-string">&quot;rótulos previstos&quot;</span>)

plot_conf_mat(y_test, y_preds)
</code></pre>
<p><img src="images/confusion-matrix.png" alt="matriz de confusão"></p>
<p>Bem melhor! Podemos ver que o modelo fica &quot;confuso&quot; prevendo o rótulo errado relativamente da mesma forma em ambas as classes. Ou seja, em 4 ocasiões o modelo previu <code>0</code> quando deveria ter previsto <code>1</code> (<em>falso negativo</em>) e em 3 ocasiões o modelo previu <code>1</code> em vez de <code>0</code> (<em>falso positivo</em>).</p>
<h2 id="relatório-de-classificação">Relatório de classificação</h2>
<p>Podemos gerar um relatório de classificação utilizando <code>class_report()</code>, inserindo os rótulos verdadeiros e os rótulos previstos dos nossos modelos. O relatório de classificação, mostra também informações sobre a precisão e revocação de nosso modelo para cada classe.</p>
<pre><code>print(classification_report(y_test, y_preds))

              precision    recall  f1-score   support

           0       0.89      0.86      0.88        29
           1       0.88      0.91      0.89        32

    accuracy                           0.89        61
   macro avg       0.89      0.88      0.88        61
weighted avg       0.89      0.89      0.89        61
</code></pre><p>Legal, temos o nosso relatório! Mas o que significa isso tudo ?
Calma, vamos por partes:</p>
<ul>
<li><strong>Precision</strong> - mostra a proporção de identificações positivas (<em>classe 1</em>) previstas no modelo, ou seja, que foram realmente corretas. Se um modelo não apresenta falsos positivos esse valor marca <code>1,0</code>.</li>
<li><strong>Recall</strong> - é o indicador de proporção de positivos reais que foram classificados corretamente. Se um modelo não produz falsos negativos então ele apresenta um <code>recall</code> de <code>1,0</code>.</li>
<li><strong>F1 score</strong> - é uma combinação de <code>Precision</code> e <code>Recall</code>. Um modelo perfeito alcança uma pontuação F1 de <code>1,0</code>.</li>
<li><strong>Support</strong> - é o número de amostras em que cada métrica foi calculada.</li>
<li><strong>Accuracy</strong> - é a precisão do modelo em formato decimal. A precisão perfeita seria igual a <code>1,0</code>.</li>
<li><strong>Macro avg</strong> - é a média de <code>Precision</code>, <code>Recall</code> e <code>F1 score</code> entre as classes.</li>
<li><strong>Weighted avg</strong> - é a média ponderada de <code>Precision</code>, <code>Recall</code> e <code>F1 score</code>. Ponderado nesse caso, significa que cada métrica é calculada em relação ao total de amostras existentes em cada classe.</li>
</ul>
<p>Pronto, agora já temos uma visão mais profunda sobre o nosso modelo. Porém, tudo foi calculado utilizando um único conjunto de dados (<em>treino e teste</em>). O que faremos agora para torná-los mais sólidos é calculá-los utilizando validação cruzada. Para isso, pegaremos o melhor modelo junto com os melhores hiperparâmetros e usaremos <code>cross_val_score()</code> junto com vários outros valores de parâmetros de pontuação.</p>
<p>A função <code>cross_val_score()</code> funciona pegando um estimador (modelo de <code>ML</code>) junto com os dados e os rótulos (labels). Em sequência, ele avalia o modelo nos dados e rótulos utilizando validação cruzada.</p>
<p>Quais são mesmo os hiperparâmetros ? Vamos lembrar:</p>
<pre><code class="lang-python">gs_log_reg.best_params_

{<span class="hljs-string">&apos;C&apos;</span>: <span class="hljs-number">0.23357214690901212</span>, <span class="hljs-string">&apos;solver&apos;</span>: <span class="hljs-string">&apos;liblinear&apos;</span>}
</code></pre>
<p>Ok, agora é instanciar o classificado com o modelo e os hiperparâmetros:</p>
<pre><code class="lang-python"><span class="hljs-comment"># Importa cross_val_score</span>
<span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> cross_val_score

<span class="hljs-comment"># Passando o melhor modelo com os melhores hiperparâmetros</span>
<span class="hljs-comment"># que encontramos com (GridSearchCV)</span>
clf = LogisticRegression(C=<span class="hljs-number">0.23357214690901212</span>,
                         solver=<span class="hljs-string">&quot;liblinear&quot;</span>)
</code></pre>
<p>Tudo pronto, vamos encontrar algumas métricas de validação cruzada:</p>
<pre><code class="lang-python"><span class="hljs-comment"># Cross-validated (validação cruzada)</span>
cv_acc = cross_val_score(clf,
                         X,
                         y,
                         cv=<span class="hljs-number">5</span>, <span class="hljs-comment"># 5-fold</span>
                         scoring=<span class="hljs-string">&quot;accuracy&quot;</span>)
cv_acc
</code></pre>
<blockquote>
<p>array([0.81967213, 0.90163934, 0.8852459 , 0.88333333, 0.75      ])</p>
</blockquote>
<p>Como existem 5 métricas, vamos calcular a média:</p>
<pre><code class="lang-python">cv_acc = np.mean(cv_acc)
cv_acc

<span class="hljs-number">0.8479781420765027</span>
</code></pre>
<p>Agora faremos a mesma coisa para outras métricas de classificação:</p>
<pre><code class="lang-python">cv_precision = np.mean(cross_val_score(clf,
                                       X,
                                       y,
                                       cv=<span class="hljs-number">5</span>,
                                       scoring=<span class="hljs-string">&quot;precision&quot;</span>))

cv_recall = np.mean(cross_val_score(clf,
                                    X,
                                    y,
                                    cv=<span class="hljs-number">5</span>,
                                    scoring=<span class="hljs-string">&quot;recall&quot;</span>))

cv_f1 = np.mean(cross_val_score(clf,
                                X,
                                y,
                                cv=<span class="hljs-number">5</span>,
                                scoring=<span class="hljs-string">&quot;f1&quot;</span>))

cv_precision, cv_recall, cv_f1
</code></pre>
<blockquote>
<p>(0.8215873015873015, 0.9272727272727274, 0.8705403543192143)</p>
</blockquote>
<p>Perfeito, temos métricas validadas cruzadas, agora vamos visualizá-las:</p>
<pre><code class="lang-python"><span class="hljs-comment"># Plot cross-validated metrics</span>
cv_metrics = pd.DataFrame({<span class="hljs-string">&quot;Accuracy&quot;</span>: cv_acc,
                            <span class="hljs-string">&quot;Precision&quot;</span>: cv_precision,
                            <span class="hljs-string">&quot;Recall&quot;</span>: cv_recall,
                            <span class="hljs-string">&quot;F1&quot;</span>: cv_f1},
                            index=[<span class="hljs-number">0</span>])
cv_metrics.T.plot.bar(title=<span class="hljs-string">&quot;Métricas de validação cruzada&quot;</span>, legend=<span class="hljs-literal">False</span>);
</code></pre>
<p><img src="images/cross-valid.png" alt="cross validate metrics"></p>
<h2 id="feature-importance">Feature importance</h2>
<p><strong>Feature importance</strong> é outra forma de perguntar que recursos contribuem mais para os resultados do modelo ?</p>
<p>Para o problema que queremos resolver, tentar prever doenças cardíacas utilizando características médicas de um paciente, quais dessas características contribuem mais para um modelo que prevê se alguém tem uma doença cardíaca ou não ? Diferente de algumas das outras funções que vimos, cada modelo encontra padrões nos dados de maneira ligeiramente diferente, a forma como um modelo julga a importância desses padrões também é diferente. Em outras palavras, para cada modelo, existe uma forma ligeiramente diferente de descobrir quais recursos foram mais importantes.</p>
<p>Como estamos utilizando <code>LogisticRegression</code>, veremos uma maneira de calcular o <code>feature importance</code> para ele. Usaremos o atributo <code>coef_</code>, que é o coeficiente dos recursos na função de decisão (<em>função que julga a importância</em>).</p>
<pre><code>clf.fit(X_train, y_train);
clf.coef_


array([[ 0.00369922, -0.9042409 ,  0.67472826, -0.0116134 , -0.00170364,
         0.04787688,  0.33490198,  0.02472938, -0.63120406, -0.5759095 ,
         0.47095141, -0.65165348, -0.69984208]])
</code></pre><p>Ok, concordo que olhando para isso não faz nenhum sentido. Mas esses valores representam o quanto cada recurso contribui na forma em que um modelo toma uma decisão sobre se os padrões em uma amostra de dados de saúde de pacientes tem maior tendência para doenças cardíacas ou não.</p>
<p>Mesmo sabendo o significado agora, esse formato atual de array ainda não faz muito sentido. Mas se combinarmos com as colunas do nosso DataFrame, pode melhorar:</p>
<pre><code class="lang-python">features_dict = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(df.columns, <span class="hljs-built_in">list</span>(clf.coef_[<span class="hljs-number">0</span>])))
features_dict


{<span class="hljs-string">&apos;age&apos;</span>: <span class="hljs-number">0.003699220776580221</span>,
 <span class="hljs-string">&apos;ca&apos;</span>: -<span class="hljs-number">0.6516534770577476</span>,
 <span class="hljs-string">&apos;chol&apos;</span>: -<span class="hljs-number">0.0017036439067759743</span>,
 <span class="hljs-string">&apos;cp&apos;</span>: <span class="hljs-number">0.6747282587404362</span>,
 <span class="hljs-string">&apos;exang&apos;</span>: -<span class="hljs-number">0.6312040612837573</span>,
 <span class="hljs-string">&apos;fbs&apos;</span>: <span class="hljs-number">0.047876881148997324</span>,
 <span class="hljs-string">&apos;oldpeak&apos;</span>: -<span class="hljs-number">0.5759095045469952</span>,
 <span class="hljs-string">&apos;restecg&apos;</span>: <span class="hljs-number">0.3349019815885189</span>,
 <span class="hljs-string">&apos;sex&apos;</span>: -<span class="hljs-number">0.9042409028785717</span>,
 <span class="hljs-string">&apos;slope&apos;</span>: <span class="hljs-number">0.4709514073081419</span>,
 <span class="hljs-string">&apos;thal&apos;</span>: -<span class="hljs-number">0.6998420764664995</span>,
 <span class="hljs-string">&apos;thalach&apos;</span>: <span class="hljs-number">0.02472938284108309</span>,
 <span class="hljs-string">&apos;trestbps&apos;</span>: -<span class="hljs-number">0.011613401339975146</span>}
</code></pre>
<p>Agora podemos visualizar:</p>
<pre><code class="lang-python">features_df = pd.DataFrame(features_dict, index=[<span class="hljs-number">0</span>])
features_df.T.plot.bar(title=<span class="hljs-string">&quot;Feature Importance&quot;</span>, legend=<span class="hljs-literal">False</span>);
</code></pre>
<p><img src="images/feature-importance.png" alt="feature importance"></p>
<p>Perceba que alguns são positivos e outros são negativos. Quanto maior o valor (maior barra), mais o recurso contribui para a decisão do modelo. Se o valor for negativo, significa que a correlação é negativa. E para valores positivos a correlação também é positiva.</p>
<p>Veja por exemplo o atributo <code>sex</code> que tem um valor negativo de <code>-0.904</code>, o que significa que a medida que o valor de <code>sex</code> aumenta, mais o valor de <code>target</code> diminui. Podemos ver isso melhor, comparando a coluna <code>sex</code> com <code>target</code>:</p>
<pre><code class="lang-python">pd.crosstab(df[<span class="hljs-string">&quot;sex&quot;</span>], df[<span class="hljs-string">&quot;target&quot;</span>])
</code></pre>
<p><img src="images/crosstab-sex-target.png" alt="crosstab sex target"></p>
<p>Podemos ver que, quando <code>sex</code> é 0 (<em>feminino</em>), há 3 vezes mais pessoas com doença cardíaca (<code>target=1</code>) do que sem. E para <code>sex</code> 1 (<em>masculino</em>), a proporção cai para quase 1 para 1 de pessoas que tem doenças cardíacas e que não tem. Isso significa que o modelo encontrou um padrão que reflete os dados, olhando para esses números e o conjunto de dados específico, parece que se o paciente é do sexo feminino, é mais provável que tenha doenças cardíacas.</p>
<hr>
<p>WIP</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="ml-101.html" class="navigation navigation-prev " aria-label="Previous page: O que é Machine Learning?">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="intro-tensorflow.html" class="navigation navigation-next " aria-label="Next page: TensorFlow">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Scikit-Learn","level":"1.3.2","depth":2,"next":{"title":"TensorFlow","level":"1.3.3","depth":2,"path":"contents/intro-tensorflow.md","ref":"contents/intro-tensorflow.md","articles":[{"title":"Tensors","level":"1.3.3.1","depth":3,"anchor":"#tensors","path":"contents/intro-tensorflow.md","ref":"contents/intro-tensorflow.md#tensors","articles":[]},{"title":"Criando Tensors com tf.constant()","level":"1.3.3.2","depth":3,"anchor":"#criando-tensors-com-tfconstant","path":"contents/intro-tensorflow.md","ref":"contents/intro-tensorflow.md#criando-tensors-com-tfconstant","articles":[]},{"title":"Criando Tensors com tf.Variable()","level":"1.3.3.3","depth":3,"anchor":"#criando-tensors-com-tfvariable","path":"contents/intro-tensorflow.md","ref":"contents/intro-tensorflow.md#criando-tensors-com-tfvariable","articles":[]}]},"previous":{"title":"O que é Machine Learning?","level":"1.3.1","depth":2,"path":"contents/ml-101.md","ref":"contents/ml-101.md","articles":[]},"articles":[{"title":"Sklearn de ponta a ponta","level":"1.3.2.1","depth":3,"anchor":"#sklearn-de-ponta-a-ponta","path":"contents/ml-sklearn.md","ref":"contents/ml-sklearn.md#sklearn-de-ponta-a-ponta","articles":[]},{"title":"EDA","level":"1.3.2.2","depth":3,"anchor":"#eda","path":"contents/ml-sklearn.md","ref":"contents/ml-sklearn.md#eda","articles":[]},{"title":"Modelagem dos dados","level":"1.3.2.3","depth":3,"anchor":"#modelagem-dos-dados","path":"contents/ml-sklearn.md","ref":"contents/ml-sklearn.md#modelagem-dos-dados","articles":[]},{"title":"Treino e Teste","level":"1.3.2.4","depth":3,"anchor":"#treino-e-teste","path":"contents/ml-sklearn.md","ref":"contents/ml-sklearn.md#treino-e-teste","articles":[]},{"title":"Escolha de modelos","level":"1.3.2.5","depth":3,"anchor":"#escolha-de-modelos","path":"contents/ml-sklearn.md","ref":"contents/ml-sklearn.md#escolha-de-modelos","articles":[]},{"title":"KNeighborsClassifier","level":"1.3.2.6","depth":3,"anchor":"#ajustando-kneighborsclassifier-knn","path":"contents/ml-sklearn.md","ref":"contents/ml-sklearn.md#ajustando-kneighborsclassifier-knn","articles":[]},{"title":"RandomizedSearchCV","level":"1.3.2.7","depth":3,"anchor":"#ajustando-modelos-com-randomizedsearchcv","path":"contents/ml-sklearn.md","ref":"contents/ml-sklearn.md#ajustando-modelos-com-randomizedsearchcv","articles":[]},{"title":"GridSearchCV","level":"1.3.2.8","depth":3,"anchor":"#ajustando-modelos-com-gridsearchcv","path":"contents/ml-sklearn.md","ref":"contents/ml-sklearn.md#ajustando-modelos-com-gridsearchcv","articles":[]},{"title":"ROC Curve e AUC Scores","level":"1.3.2.9","depth":3,"anchor":"#roc-curve-e-auc-scores","path":"contents/ml-sklearn.md","ref":"contents/ml-sklearn.md#roc-curve-e-auc-scores","articles":[]},{"title":"Feature importance","level":"1.3.2.10","depth":3,"anchor":"#feature-importance","path":"contents/contents-sklearn.md","ref":"contents/contents-sklearn.md#feature-importance","articles":[]}],"dir":"ltr"},"config":{"plugins":[],"root":"./","styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","honkit":">= 3.0.0","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"gitbook":"*"},"file":{"path":"contents/ml-sklearn.md","mtime":"2022-02-18T03:34:08.328Z","type":"markdown"},"gitbook":{"version":"3.7.1","time":"2022-02-19T11:37:50.287Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

